# -*- coding: utf-8 -*-
"""gei_based_person_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fg-1wbnZTa0vJ8D7vNcSrLXLh2MClTE4

## Installs
"""

!pip install -q ultralytics opencv-python-headless numpy scikit-image
!pip install -q mediapipe

"""## Code"""

import cv2
import os
import numpy as np
from ultralytics import YOLO
from skimage.metrics import mean_squared_error
from skimage.transform import resize
import mediapipe as mp
from google.colab.patches import cv2_imshow

# Load YOLOv8 model
model = YOLO('yolov8n.pt')

# Paths
video_path = 'walking_man.mp4'
output_dir = 'person_frames'
gei_dir = 'gei_images'
bounding_box_dir = 'bounding_boxes'
os.makedirs(output_dir, exist_ok=True)
os.makedirs(gei_dir, exist_ok=True)
os.makedirs(bounding_box_dir, exist_ok=True)

# Set the fixed size for all person bounding boxes
FIXED_SIZE = (128, 64)

# MediaPipe segmentation model
mp_selfie_segmentation = mp.solutions.selfie_segmentation.SelfieSegmentation(model_selection=1)

# Function to extract frames from the video
def extract_frames(video_path, start_frame, end_frame):
    cap = cv2.VideoCapture(video_path)
    frames = []
    frame_count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret or frame_count > end_frame:
            break
        if start_frame <= frame_count <= end_frame:
            frames.append(frame)
        frame_count += 1
    cap.release()
    return frames

# Function to generate a silhouette using MediaPipe
def generate_silhouette(image):
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = mp_selfie_segmentation.process(rgb_image)
    mask = results.segmentation_mask
    silhouette = np.zeros_like(image)
    silhouette[mask > 0.5] = 255
    return silhouette

# Function to resize and normalize person crops
def preprocess_person_crop(crop):
    silhouette = generate_silhouette(crop)  # Create a silhouette
    resized_silhouette = resize(silhouette, FIXED_SIZE, anti_aliasing=True)
    return (resized_silhouette * 255).astype(np.uint8)

# Function to calculate GEI (averaging the frames)
def calculate_gei(person_frames):
    gei = np.zeros(FIXED_SIZE + (3,), dtype=np.float32)
    for frame in person_frames:
        gei += frame.astype(np.float32)
    gei /= len(person_frames)
    return gei.astype(np.uint8)

# Function to save frames of detected persons, bounding boxes, and calculate GEI
def save_person_frames(frames, start_frame=0, end_frame=20):
    person_dict = {}
    original_bounding_box_images = {}

    for i, frame in enumerate(frames):
        results = model(frame)
        for j, box in enumerate(results[0].boxes):
            if results[0].names[int(box.cls)] == 'person':
                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                person_crop = frame[y1:y2, x1:x2]
                person_crop = preprocess_person_crop(person_crop)

                person_id = f'person_{j}'
                person_path = os.path.join(output_dir, f'{person_id}_frame_{start_frame + i}.jpg')
                cv2.imwrite(person_path, person_crop)

                if person_id not in person_dict:
                    person_dict[person_id] = []
                    # Save the first bounding box image for each person
                    bounding_box_image_path = os.path.join(bounding_box_dir, f'{person_id}_bounding_box.jpg')
                    cv2.imwrite(bounding_box_image_path, frame[y1:y2, x1:x2])
                    original_bounding_box_images[person_id] = bounding_box_image_path

                person_dict[person_id].append(person_crop)

    gei_dict = {}
    for person_id, person_frames in person_dict.items():
        gei = calculate_gei(person_frames)
        gei_path = os.path.join(gei_dir, f'{person_id}_gei.jpg')
        cv2.imwrite(gei_path, gei)
        gei_dict[person_id] = gei
    return gei_dict, original_bounding_box_images

# Function to match a frame's person to the closest GEI based on MSE
def match_person_with_gei(person_frame, gei_dict):
    resized_person = resize(person_frame, FIXED_SIZE, anti_aliasing=True)
    best_match_id = None
    min_mse = float('inf')
    for person_id, gei in gei_dict.items():
        resized_gei = resize(gei, FIXED_SIZE, anti_aliasing=True)
        mse = mean_squared_error(resized_person, resized_gei)
        if mse < min_mse:
            min_mse = mse
            best_match_id = person_id
    return best_match_id, min_mse

# Main function to process the video
def process_video(video_path):
    # Step 1: Extract frames 0-20 and calculate GEI
    initial_frames = extract_frames(video_path, start_frame=0, end_frame=20)
    gei_dict, original_bounding_box_images = save_person_frames(initial_frames)

    # Step 2: Extract frames 21-30 and perform matching
    matching_frames = extract_frames(video_path, start_frame=21, end_frame=30)
    for i, frame in enumerate(matching_frames):
        results = model(frame)
        for box in results[0].boxes:
            if results[0].names[int(box.cls)] == 'person':
                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                person_crop = frame[y1:y2, x1:x2]
                silhouette_crop = preprocess_person_crop(person_crop)
                matched_person_id, score = match_person_with_gei(silhouette_crop, gei_dict)

                if matched_person_id:
                    print(f'Frame {21 + i}: Matched with {matched_person_id} (MSE score: {score:.4f})')

                    # Display the original frame and matched person's bounding box image
                    cv2_imshow(frame)  # Show the original frame
                    matched_bounding_box_img = cv2.imread(original_bounding_box_images[matched_person_id])
                    cv2_imshow(matched_bounding_box_img)  # Show the bounding box image
                    cv2_imshow(gei_dict[matched_person_id])  # Show the matched person's GEI

                    # Save the matched frame
                    match_path = os.path.join(output_dir, f'{matched_person_id}_matched_frame_{21 + i}.jpg')
                    cv2.imwrite(match_path, person_crop)

process_video(video_path)

